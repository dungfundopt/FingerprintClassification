{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Admin\\\\FingerprintClassification\\\\model\")\n",
    "from preprocess.preprocessing3 import preprocessing_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(label2num):\n",
    "    id_anh = 0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    #output_folder = \"C:\\\\Users\\\\ADMIN\\\\FingerprintClassification\\\\model\\\\preprocessed_fingerprint\"\n",
    "    for label in os.listdir(os.path.join(\"preprocessed_fingerprint\")):\n",
    "        id_anh+=1\n",
    "        img = cv2.imread(os.path.join('preprocessed_fingerprint',str(id_anh)+'.png'))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint\"])\n",
    "        if id_anh>=4000: break\n",
    "    for label in os.listdir(os.path.join(\"preprocessed_fingerprint\")):\n",
    "        id_anh+=1\n",
    "        img = cv2.imread(os.path.join('preprocessed_fingerprint',str(id_anh)+'.png'))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint_noise\"])\n",
    "        if id_anh>=8000: break\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(label2num):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for label in os.listdir(os.path.join(\"fingerprint\")):\n",
    "        img = cv2.imread(os.path.join('fingerprint',label))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint\"])\n",
    "    for label in os.listdir(os.path.join(\"fingerprint_noise\")):\n",
    "        img = cv2.imread(os.path.join('fingerprint_noise',label))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint_noise\"])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "label2num = {'fingerprint_noise':0, 'fingerprint':1}\n",
    "X, Y = read_data(label2num)\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[7750], cmap='gray')\n",
    "print(X[7750].shape)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = (8, 8)  # h x w in pixels\n",
    "block_size = (2, 2)  # h x w in cells\n",
    "nbins = 9  # number of orientation bins\n",
    "def hist_vec(X):\n",
    "    vector_HoG = []\n",
    "    for i in range(len(X)):\n",
    "        img = X[i]\n",
    "        img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "        # 1. Khai báo các tham số\n",
    "        #cell_size = (8, 8)  # h x w in pixels\n",
    "        #block_size = (2, 2)  # h x w in cells\n",
    "        #nbins = 9  # number of orientation bins\n",
    "\n",
    "        # 2. Tính toán các tham số truyền vào HOGDescriptor\n",
    "        # winSize: Kích thước của bức ảnh được crop để chia hết cho cell size.\n",
    "        # blockSize: Kích thước của 1 block\n",
    "        blockSize = (block_size[1] * cell_size[1], block_size[0] * cell_size[0])\n",
    "        # blockStride: Số bước di chuyển của block khi thực hiện chuẩn hóa histogram bước 3\n",
    "        blockStride = (cell_size[1], cell_size[0])\n",
    "\n",
    "        # 3. Compute HOG descriptor\n",
    "        hog = cv2.HOGDescriptor(_winSize=img.shape,\n",
    "                                _blockSize=blockSize,\n",
    "                                _blockStride=blockStride,\n",
    "                                _cellSize=cell_size,\n",
    "                                _nbins=nbins)\n",
    "\n",
    "        # Kích thước của lưới ô vuông.\n",
    "        n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n",
    "        \n",
    "        # Reshape hog feature\n",
    "        hog_feats = hog.compute(img)\\\n",
    "                    .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                                n_cells[0] - block_size[0] + 1,\n",
    "                                block_size[0], block_size[1], nbins) \\\n",
    "                    .transpose((1, 0, 2, 3, 4))  \n",
    "        #H = feature.hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "        #            cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2\")\n",
    "        H = hog_feats.flatten()\n",
    "        vector_HoG.append(H)\n",
    "        #print('Kích thước hog features: ', H.shape)\n",
    "    return vector_HoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_HoG = hist_vec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước hog features:  (34596,)\n"
     ]
    }
   ],
   "source": [
    "print('Kích thước hog features: ', vector_HoG[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca(image_descriptors):\n",
    "    \n",
    "    pca = PCA(n_components=100)\n",
    "\n",
    "    # Fit và transform dữ liệu\n",
    "    pca.fit(image_descriptors)\n",
    "    des_pca = pca.transform(image_descriptors)\n",
    "    return des_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_HoG = pca(vector_HoG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước hog features:  (100,)\n"
     ]
    }
   ],
   "source": [
    "print('Kích thước hog features: ', pca_HoG[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, learning_curve, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800   1600   1600\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(len(X_train), \" \",len(X_valid), \" \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8125\n",
      "True Vali accuracy: 0.5\n",
      "Validation accuracy: 0.8197916666666667\n",
      "True Vali accuracy: 0.5025\n",
      "Validation accuracy: 0.8354166666666667\n",
      "True Vali accuracy: 0.51\n",
      "Validation accuracy: 0.8166666666666667\n",
      "True Vali accuracy: 0.500625\n",
      "Validation accuracy: 0.78125\n",
      "True Vali accuracy: 0.4975\n",
      "Average validation accuracy: 0.813125\n",
      "Average true vali accuracy: 0.502125\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo KFold với k=5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình (ví dụ: Random Forest)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Lưu trữ kết quả\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    #print(val_index)\n",
    "    # Chia tập train thành train và validation cho mỗi fold\n",
    "    #X_train_fold, X_val_fold = X_train[np.array(train_index)], X_train[np.array(val_index)]\n",
    "    #y_train_fold, y_val_fold = Y_train[np.array(train_index)], Y_train[np.array(val_index)]\n",
    "    X_train_fold = []\n",
    "    y_train_fold = []\n",
    "    X_val_fold = []\n",
    "    y_val_fold = []\n",
    "    for sg in train_index:\n",
    "        X_train_fold.append(X_train[sg])\n",
    "        y_train_fold.append(Y_train[sg])\n",
    "    #print(len(X_train_fold), len(X_val_fold), len(y_train_fold), len(y_val_fold))\n",
    "    for sg in val_index:\n",
    "        #print(sg)\n",
    "        X_val_fold.append(X_train[sg])\n",
    "        y_val_fold.append(Y_train[sg])\n",
    "    # Huấn luyện mô hình trên tập train_fold\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Đánh giá trên tập validation\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Đánh giá trên tập test (độc lập)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(Y_valid, y_test_pred)\n",
    "    print(f\"True Vali accuracy: {test_accuracy}\")\n",
    "\n",
    "    results.append({'val_accuracy': val_accuracy, 'test_accuracy': test_accuracy})\n",
    "\n",
    "# In kết quả trung bình\n",
    "print(\"Average validation accuracy:\", sum(result['val_accuracy'] for result in results) / len(results))\n",
    "print(\"Average true vali accuracy:\", sum(result['test_accuracy'] for result in results) / len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3196, number of negative: 3204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 918000\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 3600\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "0.99953125\n",
      "0.759375\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier(class_weight=\"balanced\").fit(X_train, Y_train)\n",
    "print(lgbm.score(X_train, Y_train))\n",
    "print(lgbm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8641666666666666\n",
      "0.783125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression().fit(X_train, Y_train)\n",
    "print(log.score(X_train, Y_train))\n",
    "print(log.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7629166666666667\n",
      "0.7525\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(algorithm='SAMME')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.score(X_train, Y_train))\n",
    "print(clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.649375\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier().fit(X_train, Y_train)\n",
    "print(dtree.score(X_train, Y_train))\n",
    "print(dtree.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7691666666666667\n",
      "0.57625\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,Y_train)\n",
    "print(knn.score(X_train, Y_train))\n",
    "print(knn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9927083333333333\n",
      "0.645625\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=12,max_depth=20)\n",
    "rf.fit(X_train, Y_train)\n",
    "print(rf.score(X_train, Y_train))\n",
    "print(rf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "sv = SVC(kernel = 'linear')\n",
    "sv.fit(X_train, Y_train)\n",
    "print(sv.score(X_train, Y_train))\n",
    "print(sv.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = SVC(kernel = 'rbf')\n",
    "sv.fit(X_train, Y_train)\n",
    "print(sv.score(X_train, Y_train))\n",
    "print(sv.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
