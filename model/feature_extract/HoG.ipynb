{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Admin\\\\FingerprintClassification\\\\model\")\n",
    "from preprocess.preprocessing3 import preprocessing_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(label2num):\n",
    "    id_anh = 0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    #output_folder = \"C:\\\\Users\\\\ADMIN\\\\FingerprintClassification\\\\model\\\\preprocessed_fingerprint\"\n",
    "    for label in os.listdir(os.path.join(\"dataset\\\\preprocessed_fingerprint\")):\n",
    "        id_anh+=1\n",
    "        img = cv2.imread(os.path.join('dataset\\\\preprocessed_fingerprint',str(id_anh)+'.png'))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint\"])\n",
    "        if id_anh>=4000: break\n",
    "    for label in os.listdir(os.path.join(\"dataset\\\\preprocessed_fingerprint\")):\n",
    "        id_anh+=1\n",
    "        img = cv2.imread(os.path.join('dataset\\\\preprocessed_fingerprint',str(id_anh)+'.png'))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint_noise\"])\n",
    "        if id_anh>=8000: break\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def read_data(label2num):\\n    X = []\\n    Y = []\\n    for label in os.listdir(os.path.join(\"dataset\\\\fingerprint\")):\\n        img = cv2.imread(os.path.join(\\'dataset\\\\fingerprint\\',label))\\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\n        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\\n        #img = img.flatten()\\n        X.append(img)\\n        Y.append(label2num[\"fingerprint\"])\\n    for label in os.listdir(os.path.join(\"dataset\\\\fingerprint_noise\")):\\n        img = cv2.imread(os.path.join(\\'dataset\\\\fingerprint_noise\\',label))\\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\n        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\\n        #img = img.flatten()\\n        X.append(img)\\n        Y.append(label2num[\"fingerprint_noise\"])\\n    return X,Y'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def read_data(label2num):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for label in os.listdir(os.path.join(\"dataset\\\\fingerprint\")):\n",
    "        img = cv2.imread(os.path.join('dataset\\\\fingerprint',label))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        #img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint\"])\n",
    "    for label in os.listdir(os.path.join(\"dataset\\\\fingerprint_noise\")):\n",
    "        img = cv2.imread(os.path.join('dataset\\\\fingerprint_noise',label))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        #img = img.flatten()\n",
    "        X.append(img)\n",
    "        Y.append(label2num[\"fingerprint_noise\"])\n",
    "    return X,Y'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "label2num = {'fingerprint_noise':0, 'fingerprint':1}\n",
    "X, Y = read_data(label2num)\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = (16, 16)  # h x w in pixels\n",
    "block_size = (8, 8)  # h x w in cells\n",
    "nbins = 4  # number of orientation bins\n",
    "def hist_vec(X):\n",
    "    vector_HoG = []\n",
    "    for i in range(len(X)):\n",
    "        img = X[i]\n",
    "        #thresh, img= cv2.threshold(img, 255, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        # 1. Khai báo các tham số\n",
    "        #cell_size = (8, 8)  # h x w in pixels\n",
    "        #block_size = (2, 2)  # h x w in cells\n",
    "        #nbins = 9  # number of orientation bins\n",
    "\n",
    "        # 2. Tính toán các tham số truyền vào HOGDescriptor\n",
    "        # winSize: Kích thước của bức ảnh được crop để chia hết cho cell size.\n",
    "        # blockSize: Kích thước của 1 block\n",
    "        blockSize = (block_size[1] * cell_size[1], block_size[0] * cell_size[0])\n",
    "        # blockStride: Số bước di chuyển của block khi thực hiện chuẩn hóa histogram bước 3\n",
    "        blockStride = (cell_size[1], cell_size[0])\n",
    "\n",
    "        # 3. Compute HOG descriptor\n",
    "        hog = cv2.HOGDescriptor(_winSize=img.shape,\n",
    "                                _blockSize=blockSize,\n",
    "                                _blockStride=blockStride,\n",
    "                                _cellSize=cell_size,\n",
    "                                _nbins=nbins)\n",
    "\n",
    "        # Kích thước của lưới ô vuông.\n",
    "        n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n",
    "        \n",
    "        # Reshape hog feature\n",
    "        hog_feats = hog.compute(img)\\\n",
    "                    .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                                n_cells[0] - block_size[0] + 1,\n",
    "                                block_size[0], block_size[1], nbins) \\\n",
    "                    .transpose((1, 0, 2, 3, 4))  \n",
    "        #H = feature.hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "        #            cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2\")\n",
    "        H = hog_feats.flatten()\n",
    "        vector_HoG.append(H)\n",
    "        #print('Kích thước hog features: ', H.shape)\n",
    "    return vector_HoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_HoG = hist_vec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước hog features:  (20736,)\n"
     ]
    }
   ],
   "source": [
    "print('Kích thước hog features: ', vector_HoG[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca(image_descriptors):\n",
    "    \n",
    "    pca = PCA(n_components=400)\n",
    "\n",
    "    # Fit và transform dữ liệu\n",
    "    pca.fit(image_descriptors)\n",
    "    des_pca = pca.transform(image_descriptors)\n",
    "    return des_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_HoG = pca(vector_HoG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước hog features:  (400,)\n"
     ]
    }
   ],
   "source": [
    "print('Kích thước hog features: ', pca_HoG[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, learning_curve, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800   1600   1600\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(pca_HoG, Y, test_size = 0.2, random_state=42)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(len(X_train), \" \",len(X_valid), \" \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Khởi tạo KFold với k=5\\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\\n\\n# Khởi tạo mô hình (ví dụ: Random Forest)\\nmodel = LogisticRegression()\\n\\n# Lưu trữ kết quả\\nresults = []\\n\\nfor train_index, val_index in kf.split(X_train):\\n    #print(val_index)\\n    # Chia tập train thành train và validation cho mỗi fold\\n    #X_train_fold, X_val_fold = X_train[np.array(train_index)], X_train[np.array(val_index)]\\n    #y_train_fold, y_val_fold = Y_train[np.array(train_index)], Y_train[np.array(val_index)]\\n    X_train_fold = []\\n    y_train_fold = []\\n    X_val_fold = []\\n    y_val_fold = []\\n    for sg in train_index:\\n        X_train_fold.append(X_train[sg])\\n        y_train_fold.append(Y_train[sg])\\n    #print(len(X_train_fold), len(X_val_fold), len(y_train_fold), len(y_val_fold))\\n    for sg in val_index:\\n        #print(sg)\\n        X_val_fold.append(X_train[sg])\\n        y_val_fold.append(Y_train[sg])\\n    # Huấn luyện mô hình trên tập train_fold\\n    model.fit(X_train_fold, y_train_fold)\\n\\n    # Đánh giá trên tập validation\\n    y_val_pred = model.predict(X_val_fold)\\n    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\\n    print(f\"Validation accuracy: {val_accuracy}\")\\n\\n    # Đánh giá trên tập test (độc lập)\\n    y_test_pred = model.predict(X_test)\\n    test_accuracy = accuracy_score(Y_valid, y_test_pred)\\n    print(f\"True Vali accuracy: {test_accuracy}\")\\n\\n    results.append({\\'val_accuracy\\': val_accuracy, \\'test_accuracy\\': test_accuracy})\\n\\n# In kết quả trung bình\\nprint(\"Average validation accuracy:\", sum(result[\\'val_accuracy\\'] for result in results) / len(results))\\nprint(\"Average true vali accuracy:\", sum(result[\\'test_accuracy\\'] for result in results) / len(results))'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Khởi tạo KFold với k=5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình (ví dụ: Random Forest)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Lưu trữ kết quả\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    #print(val_index)\n",
    "    # Chia tập train thành train và validation cho mỗi fold\n",
    "    #X_train_fold, X_val_fold = X_train[np.array(train_index)], X_train[np.array(val_index)]\n",
    "    #y_train_fold, y_val_fold = Y_train[np.array(train_index)], Y_train[np.array(val_index)]\n",
    "    X_train_fold = []\n",
    "    y_train_fold = []\n",
    "    X_val_fold = []\n",
    "    y_val_fold = []\n",
    "    for sg in train_index:\n",
    "        X_train_fold.append(X_train[sg])\n",
    "        y_train_fold.append(Y_train[sg])\n",
    "    #print(len(X_train_fold), len(X_val_fold), len(y_train_fold), len(y_val_fold))\n",
    "    for sg in val_index:\n",
    "        #print(sg)\n",
    "        X_val_fold.append(X_train[sg])\n",
    "        y_val_fold.append(Y_train[sg])\n",
    "    # Huấn luyện mô hình trên tập train_fold\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Đánh giá trên tập validation\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Đánh giá trên tập test (độc lập)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(Y_valid, y_test_pred)\n",
    "    print(f\"True Vali accuracy: {test_accuracy}\")\n",
    "\n",
    "    results.append({'val_accuracy': val_accuracy, 'test_accuracy': test_accuracy})\n",
    "\n",
    "# In kết quả trung bình\n",
    "print(\"Average validation accuracy:\", sum(result['val_accuracy'] for result in results) / len(results))\n",
    "print(\"Average true vali accuracy:\", sum(result['test_accuracy'] for result in results) / len(results))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2395, number of negative: 2405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 102000\n",
      "[LightGBM] [Info] Number of data points in the train set: 4800, number of used features: 400\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "0.9820833333333333\n",
      "0.805625\n",
      "0.831875\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier(class_weight=\"balanced\",num_leaves=15).fit(X_train, Y_train)\n",
    "print(lgbm.score(X_train, Y_train))\n",
    "print(lgbm.score(X_valid, Y_valid))\n",
    "print(lgbm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77875\n",
      "0.74125\n",
      "0.76125\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression().fit(X_train, Y_train)\n",
    "print(log.score(X_train, Y_train))\n",
    "print(log.score(X_valid, Y_valid))\n",
    "print(log.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788125\n",
      "0.728125\n",
      "0.766875\n"
     ]
    }
   ],
   "source": [
    "sv = SVC(kernel = 'linear')\n",
    "sv.fit(X_train, Y_train)\n",
    "print(sv.score(X_train, Y_train))\n",
    "print(sv.score(X_valid, Y_valid))\n",
    "print(sv.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8608333333333333\n",
      "0.69875\n",
      "0.71875\n"
     ]
    }
   ],
   "source": [
    "svp = SVC(kernel = 'poly')\n",
    "svp.fit(X_train, Y_train)\n",
    "print(svp.score(X_train, Y_train))\n",
    "print(svp.score(X_valid, Y_valid))\n",
    "print(svp.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9852083333333334\n",
      "0.7975\n",
      "0.783125\n"
     ]
    }
   ],
   "source": [
    "svr = SVC(kernel = 'rbf', C=11, gamma=0.04)\n",
    "svr.fit(X_train, Y_train)\n",
    "print(svr.score(X_train, Y_train))\n",
    "print(svr.score(X_valid, Y_valid))\n",
    "print(svr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báo cáo đánh giá trên tập huấn luyện:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2405\n",
      "           1       0.98      0.99      0.99      2395\n",
      "\n",
      "    accuracy                           0.99      4800\n",
      "   macro avg       0.99      0.99      0.99      4800\n",
      "weighted avg       0.99      0.99      0.99      4800\n",
      "\n",
      "Báo cáo đánh giá trên tập kiểm tra:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       796\n",
      "           1       0.76      0.83      0.79       804\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.79      0.78      0.78      1600\n",
      "weighted avg       0.79      0.78      0.78      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_train = svr.predict(X_train)\n",
    "y_pred_test = svr.predict(X_test)\n",
    "# Tính các chỉ số\n",
    "print(\"Báo cáo đánh giá trên tập huấn luyện:\")\n",
    "print(classification_report(Y_train, y_pred_train))\n",
    "\n",
    "print(\"Báo cáo đánh giá trên tập kiểm tra:\")\n",
    "print(classification_report(Y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
