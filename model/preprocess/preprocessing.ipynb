{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "#import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_border(image, crop_pixels):\n",
    "    # Load the image\n",
    "    #image_path = \n",
    "    #image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply a binary threshold to separate the fingerprint from the background\n",
    "    _, thresh = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # If no contours are found, return the original image\n",
    "    if not contours:\n",
    "        return image\n",
    "    \n",
    "    # Find the bounding rectangle of the largest contour\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Adjust the coordinates to crop the specified number of pixels from the border\n",
    "    x = max(x + crop_pixels, 0)  # Ensure x does not go negative\n",
    "    y = max(y + crop_pixels, 0)  # Ensure y does not go negative\n",
    "    w = max(w - 2 * crop_pixels, 0)  # Reduce width\n",
    "    h = max(h - 2 * crop_pixels, 0)  # Reduce height\n",
    "    \n",
    "    # Crop the image to the adjusted bounding rectangle\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "\n",
    "    '''cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', cropped_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()'''\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_based_on_intensity(image, threshold=240):\n",
    "    # Convert to grayscale if necessary\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) > 2 else image\n",
    "\n",
    "    # Threshold the background\n",
    "    _, mask = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        # Get the bounding box of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        cropped_image = image[y:y+h, x:x+w]\n",
    "        return cropped_image\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmented_and_variance_images(im, w, threshold=.2):\n",
    "    \"\"\"\n",
    "    Returns mask identifying the ROI. Calculates the standard deviation in each image block and threshold the ROI\n",
    "    It also normalises the intesity values of\n",
    "    the image so that the ridge regions have zero mean, unit standard\n",
    "    deviation.\n",
    "    :param im: Image\n",
    "    :param w: size of the block\n",
    "    :param threshold: std threshold\n",
    "    :return: segmented_image\n",
    "    \"\"\"\n",
    "    (y, x) = im.shape\n",
    "    threshold = np.std(im)*threshold\n",
    "\n",
    "    image_variance = np.zeros(im.shape)\n",
    "    segmented_image = im.copy()\n",
    "    mask = np.ones_like(im)\n",
    "\n",
    "    for i in range(0, x, w):\n",
    "        for j in range(0, y, w):\n",
    "            box = [i, j, min(i + w, x), min(j + w, y)]\n",
    "            block_stddev = np.std(im[box[1]:box[3], box[0]:box[2]])\n",
    "            image_variance[box[1]:box[3], box[0]:box[2]] = block_stddev\n",
    "\n",
    "    # apply threshold\n",
    "    mask[image_variance < threshold] = 0\n",
    "\n",
    "    # smooth mask with a open/close morphological filter\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(w*2, w*2))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # normalize segmented image\n",
    "    segmented_image *= mask\n",
    "    #im = normalise(im)\n",
    "    mean_val = np.mean(im[mask==0])\n",
    "    std_val = np.std(im[mask==0])\n",
    "    norm_img = (im - mean_val)/(std_val)\n",
    "\n",
    "    return segmented_image, norm_img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.morphology import skeletonize as skelt\n",
    "from skimage.morphology import thin\n",
    "def skeletonizee(image_input):\n",
    "    image = np.zeros_like(image_input)\n",
    "    image[image_input == 0] = 1.0\n",
    "    output = np.zeros_like(image_input)\n",
    "\n",
    "    skeleton = skelt(image)\n",
    "\n",
    "    output[skeleton] = 255\n",
    "    cv2.bitwise_not(output, output)\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe_contrast(a):\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0)\n",
    "    #b = a\n",
    "    a = clahe.apply(a)#4\n",
    "    '''cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()'''\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixel(x, v0, v, m, m0):\n",
    "    \"\"\"\n",
    "    From Handbook of Fingerprint Recognition pg 133\n",
    "    Normalize job used by Hong, Wan and Jain(1998)\n",
    "    similar to https://pdfs.semanticscholar.org/6e86/1d0b58bdf7e2e2bb0ecbf274cee6974fe13f.pdf equation 21\n",
    "    :param x: pixel value\n",
    "    :param v0: desired variance\n",
    "    :param v: global image variance\n",
    "    :param m: global image mean\n",
    "    :param m0: desired mean\n",
    "    :return: normilized pixel\n",
    "    \"\"\"\n",
    "    dev_coeff = sqrt((v0 * ((x - m)**2)) / v)\n",
    "    return m0 + dev_coeff if x > m else m0 - dev_coeff\n",
    "\n",
    "def normalize(im, m0, v0):\n",
    "    m = np.mean(im)\n",
    "    v = np.std(im) ** 2\n",
    "    (y, x) = im.shape\n",
    "    normilize_image = im.copy()\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            normilize_image[j, i] = normalize_pixel(im[j, i], v0, v, m, m0)\n",
    "\n",
    "    return normilize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_normal(path):\n",
    "    #filee=file[:-4]\n",
    "    a = cv2.imread(path, cv2.IMREAD_GRAYSCALE)#convert the image to grayscale #1\n",
    "    #a = remove_border(a, 2)#2\n",
    "        \n",
    "    '''a = crop_based_on_intensity(a)#2\n",
    "    print('Cropped')\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()'''\n",
    "\n",
    "    a = normalize(a.copy(), float(100), float(100))#2\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    #b = clahe_contrast(a)\n",
    "    #segment(3)\n",
    "    #(a, normim, mask) = create_segmented_and_variance_images(a, 8, 0.2)\n",
    "    #print(a.shape)\n",
    "\n",
    "    #a = cv2.resize(a, (512, 512), interpolation=cv2.INTER_CUBIC) #inter_cubic phù hợp tăng kích thước ảnh 3\n",
    "    #print(a.shape)\n",
    "    #a = gabor_filter(a)\n",
    "    a = clahe_contrast(a)#3\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    #4 binarization\n",
    "    thresh, a= cv2.threshold(a, 255, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    a = crop_using_morphology(a)\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    a = cv2.resize(a, (512, 512), interpolation=cv2.INTER_CUBIC) #5 inter_cubic phù hợp tăng kích thước ảnh\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(a.shape)\n",
    "    \n",
    "    '''(a, normim, mask) = create_segmented_and_variance_images(a, 8, 0.2)\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', a)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()'''\n",
    "\n",
    "    #skeletonize(5)(chắc  bỏ)\n",
    "    #a = skeletonizee(a)\n",
    "    \n",
    "\n",
    "    \n",
    "       \n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_using_morphology(image):\n",
    "    # Check if the image is grayscale (1 channel) or color (3 channels)\n",
    "    if len(image.shape) == 2:  # Grayscale image\n",
    "        gray = image  # No conversion needed\n",
    "    elif len(image.shape) == 3 and image.shape[2] == 3:  # Color image\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid image format: The image must be either grayscale or color (BGR).\")\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Morphological closing to connect ridge lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Find contours and crop based on the largest contour\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        cropped_image = image[y:y+h, x:x+w]\n",
    "        return cropped_image\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_using_itself(img1,img2):\n",
    "    result = np.zeros_like(img1)\n",
    "    print(img1.shape)\n",
    "    print(img2.shape)\n",
    "    # Lặp qua từng pixel\n",
    "    for i in range(img1.shape[0]):\n",
    "        for j in range(img1.shape[1]):\n",
    "            if img1[i, j] < img2[i, j]:\n",
    "                result[i, j] = img2[i, j]\n",
    "            else:\n",
    "                result[i, j] = 255\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_openandclose(img):\n",
    "    kernel = np.ones((5, 5), np.uint8) \n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) \n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel) \n",
    "    # Tìm các contour trong ảnh sau khi xử lý \n",
    "    contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Chọn contour lớn nhất đại diện cho vùng vân tay \n",
    "    largest_contour = max(contours, key=cv2.contourArea) \n",
    "    # Lấy bounding box của contour lớn nhất \n",
    "    x, y, w, h = cv2.boundingRect(largest_contour) \n",
    "    # Cắt ảnh dựa trên bounding box \n",
    "    cropped_image = img[y:y+h, x:x+w]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 104 is out of bounds for axis 1 with size 92",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m, in \u001b[0;36mon_mouse\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_mouse\u001b[39m(event, x, y, flags, param):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_LBUTTONDOWN:\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToa do: (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m), Gia tri pixel: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (x, y, \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m))\n",
      "\u001b[1;31mIndexError\u001b[0m: index 104 is out of bounds for axis 1 with size 92"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print('Toa do: (%d, %d), Gia tri pixel: %d' % (x, y, a[y, x]))\n",
    "\n",
    "# Đọc ảnh xám\n",
    "a = cv2.imread(\"C:\\\\Users\\\\Admin\\\\FingerprintClassification\\\\testjuan\\\\r1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "a = normalize(a, float(100), float(100))\n",
    "#thresh, b= cv2.threshold(a, 255, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#print(b)\n",
    "#a = clahe_contrast(a)\n",
    "#a = normalize(a, float(150), float(50))\n",
    "thresh, a= cv2.threshold(a, 255, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#a = crop_using_morphology(a)\n",
    "#a = cv2.GaussianBlur(a, (3,3), 0)\n",
    "# Tạo cửa sổ và liên kết hàm callback\n",
    "a = crop_openandclose(a)\n",
    "cv2.namedWindow('Anh xam')\n",
    "cv2.setMouseCallback('Anh xam', on_mouse)\n",
    "\n",
    "# Hiển thị ảnh\n",
    "cv2.imshow('Anh xam', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths for images\n",
    "# 'C:\\\\Users\\\\84965\\\\Documents\\\\Fingerprint_Recognition_GROUP8\\\\model\\\\anhhvantay\\\\R_f0002_05.png'\n",
    "# C:\\\\Users\\\\84965\\\\Documents\\\\Fingerprint_Recognition_GROUP8\\\\test\\\\batch3_R_f0002_05.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "image_path = 'C:\\\\Users\\\\84965\\\\Documents\\\\Fingerprint_Recognition_GROUP8\\\\model\\\\anhhvantay\\\\R_f0002_05.png'\n",
    "img = preprocessing_normal(image_path)\n",
    "cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('test', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "image_folder = \"C:\\\\Users\\\\Admin\\\\FingerprintClassification\\\\testjuan\"\n",
    "for filename in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    img = preprocessing_normal(image_path)\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_link = 'C:\\\\Users\\\\Admin\\\\Fingerprint_Recognition_GROUP8\\\\khunglongxanh.jpg'\n",
    "image = cv2.imread(image_link, cv2.IMREAD_GRAYSCALE)\n",
    "    # Create a kernel for erosion and dilation\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "skel = np.ones(image.shape, np.uint8)\n",
    "    \n",
    "    # Store the previous image to check if any changes happen\n",
    "prev_image = np.copy(image)\n",
    "    \n",
    "while True:\n",
    "        # Erode the image\n",
    "    eroded = cv2.erode(image, kernel)\n",
    "    \n",
    "        # If erosion doesn't change the image, break the loop\n",
    "    if np.array_equal(eroded, prev_image):\n",
    "        break\n",
    "        \n",
    "        # Subtract eroded from the original image\n",
    "    temp = cv2.dilate(eroded, kernel)\n",
    "    temp = cv2.subtract(image, temp)\n",
    "    \n",
    "        # Update skeleton\n",
    "    skel = cv2.bitwise_or(skel, temp)\n",
    "    \n",
    "        # Update image for the next iteration\n",
    "    prev_image = np.copy(eroded)\n",
    "    image[:] = eroded\n",
    "cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('test', skel)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
